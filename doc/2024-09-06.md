I was able to use mediapipe to get face and hand landmarks[1] in real time. It was much faster than my version with python. I'll write more details about mediapipe later[2]. I'll write some code to check if the hand is in front of the mouth and whether the hand is in a pinching motion (to hold a pill). We can train an ML model taking in the landmarks to replace this later if necessary. I should also be able to do background subtraction on the side and check if that's good enough to detect falling pills. Finally I should be able to run this in android soon, which will be helpful to understand what the constraints are on a phone.

![mediapipe-landmarks](/doc/multimedia/landmarks-demo.jpg)

I didn't explain my idea of how the phone will be used exactly. I have to make the use-case slides tomorrow so I'll share them here after and add some more explanations. [Here are the scope slides](/doc/multimedia/group_b_slides.pdf). I forgot group members don't have access to the google drive for submissions.

[1] - Landmarks here just mean the positions of important places like the tips and knuckles of 5 fingers, the eyes, various points on the mouth. Refer to the image.
[2] - I'll probably have to make a fork of mediapipe in a separate repo because it's confusing otherwise.
